{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translating deep learning code \n",
    "### from Pytorch to TensorFlow \n",
    "\n",
    "\n",
    "This notebook contains both Tensorflow and Pytorch versions of functions from the Paper: ***Variational fair Information bottlekneck***. \n",
    "\n",
    "- The original PyTorch functions were retrieved from the author's GitHub repo, which can be found at: https://github.com/sajadn/Variational-Fair-Information-Bottleneck\n",
    "\n",
    "\n",
    "Notebook Author : Niloy Purkait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "import numpy as np\n",
    "import torch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numpy: 1.19.2\nPytorch: 1.7.1\nTensorFlow: 2.4.1\nkeras: 2.4.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"numpy: {np.__version__}\")\n",
    "print(f\"Pytorch: {torch.__version__}\")\n",
    "print(f\"TensorFlow: {tf.__version__}\")\n",
    "print(f\"keras: {tf.keras.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make some random arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dim = 110\n",
    "batch_size = 128\n",
    "latent_size = 50\n",
    "\n",
    "X = np.random.binomial(1, 0.5, size=(batch_size, feature_dim))\n",
    "y = np.random.binomial(1, 0.5, size=(batch_size, 1))\n",
    "\n",
    "z_mean, z_log_sigma, z = np.random.normal(size=(3, batch_size, latent_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(torch.Size([128, 110]), TensorShape([128, 110]))"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "X_tf = tf.constant(X, dtype=tf.float32)\n",
    "y_tf = tf.constant(y, dtype=tf.float32)\n",
    "\n",
    "X_pt = torch.FloatTensor(X)\n",
    "y_pt = torch.FloatTensor(y)\n",
    "\n",
    "X_pt.shape, X_tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_m_tf, z_l_s_tf, z_tf = [tf.constant(x, dtype=tf.float32) for x in [z_mean, z_log_sigma, z]]\n",
    "z_m_pt, z_l_s_pt, z_pt = [torch.FloatTensor(x) for x in [z_mean, z_log_sigma, z]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch\n",
    "def entropy_gaussian(mu, sigma, mean=True):\n",
    "    msigma = sigma.view(sigma.shape[0], -1)\n",
    "    return torch.mean(0.5*(msigma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TensorFlow\n",
    "def tf_entropy_gaussian(mu, sigma, mean=True):\n",
    "    msigma = tf.reshape(sigma, (K.shape(sigma)[0], -1))\n",
    "    return tf.reduce_mean(0.5*msigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(-0.0062)"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "# Pytorch test\n",
    "entropy_gaussian(z_m_pt, z_l_s_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=-0.0061686565>"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "# TensorFlow test\n",
    "tf_entropy_gaussian(z_m_tf, z_l_s_tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Negative Log Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def negative_log_gaussian(data, mu, sigma, mean=True):\n",
    "    EPSILON = torch.tensor(10e-25).double()\n",
    "    mdata = data.view(data.shape[0], -1)\n",
    "    mmu = mu.view(data.shape[0], -1)\n",
    "    msigma = sigma.view(data.shape[0], -1)\n",
    "    return 0.5*torch.mean((mdata-mmu)**2/(torch.exp(msigma)+EPSILON) + msigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def tf_negative_log_gaussian(data, mu, sigma, mean=True):\n",
    "    EPSILON = tf.constant([10e-25])\n",
    "    mdata = tf.reshape(data, (K.shape(data)[0], -1))\n",
    "    mmu = tf.reshape(mu, (K.shape(data)[0], -1))\n",
    "    \n",
    "    msigma = tf.reshape(sigma, (K.shape(data)[0], -1))\n",
    "\n",
    "    return 0.5 * tf.reduce_mean((mdata-mmu)**2/(K.exp(msigma)+EPSILON) + msigma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(0.2476)"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "\n",
    "negative_log_gaussian(X_pt,X_pt,X_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.24758522>"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "#TensorFlow test\n",
    "tf_negative_log_gaussian(X_tf,X_tf,X_tf,)"
   ]
  },
  {
   "source": [
    "## Negative log bernoulli"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch\n",
    "log_sigmoid = torch.nn.LogSigmoid()\n",
    "def negative_log_bernoulli(data, mu, mean=True, clamp=True):\n",
    "    if clamp:\n",
    "        mu = torch.clamp(mu, min=-9.5, max=9.5)\n",
    "    mdata = data.view(data.shape[0], -1)\n",
    "    mmu = mu.view(data.shape[0], -1)\n",
    "    log_prob_1 = log_sigmoid(mmu)\n",
    "    log_prob_2 = log_sigmoid(-mmu)\n",
    "    log_likelihood = -torch.mean((mdata*log_prob_1)+(1-mdata)*log_prob_2)\n",
    "    return log_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_negative_log_bernoulli(data, mu, mean=True, clamp=True):\n",
    "    cast_shape = lambda x, d : tf.reshape(x, (K.shape(d)[0],-1))\n",
    "    if clamp:\n",
    "        mu = K.clip(mu, -9.5, 9.5)\n",
    "\n",
    "    \n",
    "    mdata = cast_shape(data, data)\n",
    "\n",
    "    mmu = cast_shape(mu, data)\n",
    "\n",
    "    log_prob_1 = tf.math.log_sigmoid(mmu)\n",
    "    log_prob_2 = tf.math.log_sigmoid(-mmu)\n",
    "    log_likelihood = -tf.reduce_mean((mdata*log_prob_1)+(1-mdata)*log_prob_2)\n",
    "    return log_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(0.5032)"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "# Pytorch test\n",
    "negative_log_bernoulli(y_pt, y_pt) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.50320446>"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "# TensorFlow test\n",
    "tf_negative_log_bernoulli(y_tf, y_tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KL Divergence loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pytorch\n",
    "def KL(mu, log_sigma):\n",
    "    return 0.5*(-log_sigma + mu**2 + log_sigma.exp()).mean()\n",
    "\n",
    "#TensorFlow\n",
    "def tf_KL(mu, log_sigma):\n",
    "    kl_loss = 0.5 * tf.reduce_mean(( - log_sigma + K.square(mu) + K.exp(log_sigma)))\n",
    "    return kl_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(1.3114)"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "#Pytorch test\n",
    "KL(z_m_pt, z_l_s_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=1.3113883>"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "#TensorFlow test\n",
    "tf_KL(z_m_tf,z_l_s_tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch\n",
    "def kernel(a, b): #N x M, K x M\n",
    "    dist1 = (a**2).sum(dim=1).unsqueeze(1).expand(-1, b.shape[0]) #N x C\n",
    "    dist2 = (b**2).sum(dim=1).unsqueeze(0).expand(a.shape[0], -1) #N x C\n",
    "    dist3 = torch.mm(a, b.transpose(0, 1))\n",
    "    dist = (dist1 + dist2) - (2 * dist3)\n",
    "    return torch.mean(torch.exp(-dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow\n",
    "def tf_kernel(a,b):\n",
    "    dist1 = tf.expand_dims(tf.math.reduce_sum((a**2), axis=1), axis=1) * tf.ones(shape=(1,b.shape[0]))\n",
    "    dist2 = tf.expand_dims(tf.math.reduce_sum((b**2), axis=1), axis=0)* tf.ones(shape=(a.shape[0], 1))\n",
    "    dist3 = tf.matmul(a, tf.transpose(b, perm=[1, 0]))\n",
    "    dist = (dist1 + dist2) - (2 * dist3)\n",
    "    return tf.reduce_mean(tf.math.exp(-dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And more random tensors\n",
    "array_pt_1 = torch.normal(mean=0, std=1, size=(4,1))\n",
    "array_pt_2 = torch.normal(mean=0, std=1, size=(2,1))\n",
    "\n",
    "# Convert to tensors\n",
    "array_tf_1, array_tf_2 = [tf.constant(x.numpy()) for x in [array_pt_1, array_pt_2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.31417778>"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "# TensorFlow test\n",
    "tf_kernel(array_tf_1,array_tf_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(0.3142)"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "# Pytorch Test\n",
    "kernel(array_pt_1,array_pt_2)"
   ]
  },
  {
   "source": [
    "## Maximum Mean Discrepancy"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mmd(X, z):    \n",
    "    sens_attr = X[:, 0].unsqueeze(1)\n",
    "    \n",
    "    z_s_0 = z[sens_attr.bool().squeeze(), :]\n",
    "    z_s_1 = z[~sens_attr.bool().squeeze(), :]\n",
    "    \n",
    "    mmd_loss = kernel(z_s_0, z_s_0) + kernel(z_s_1, z_s_1) - 2 * kernel(z_s_0, z_s_1)\n",
    "    return mmd_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_mmd(X, z):\n",
    "    z_s_0 = tf.gather(z, tf.where(X[:,0]==0))\n",
    "    z_s_1 = tf.gather(z, tf.where(X[:,0]==1))\n",
    "    \n",
    "    z_s_0 = tf.reshape(z_s_0, (K.shape(z_s_0)[0], K.shape(z_s_0)[-1]))\n",
    "    z_s_1 = tf.reshape(z_s_1, (K.shape(z_s_1)[0], K.shape(z_s_1)[-1]))\n",
    "\n",
    "    loss = tf_kernel(z_s_0, z_s_0) + tf_kernel(z_s_1, z_s_1) - 2 * tf_kernel(z_s_0, z_s_1)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(0.0313)"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "mmd(X_pt, z_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.031257637>"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "tf_mmd(X_tf, z_tf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}