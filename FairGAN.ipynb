{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0f6f723b4740d5069e80b8f886fa652add3acfda91f477f6cb179a83efd55ac03",
   "display_name": "Python 3.8.5 64-bit (conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# FairGAN \n",
    "\n",
    "Learning data representations with high utility and high fairness using an adverserial approach.\n",
    "\n",
    "- Utility : w.r.t. classification goals\n",
    "- Fairness : w.r.t difference in likelyhood of outcomes for protected groups (i.e. gender =  Male | Female)\n",
    "\n",
    "## Structure of FairGAN\n",
    "<img src=\"FairGANModel.png\" width=\"400\">\n",
    "\n",
    "### Implemented in tensorflow\n",
    "### source : https://arxiv.org/pdf/1805.11202.pdf\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from preprocess_adult import *\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, LeakyReLU\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def split_tensor(tensor, col_name, n=1):\n",
    "    '''takes Xn (2D feature tensor) and returns 2 tensors(sensitive features and normal features)'''\n",
    "    col = Xys_cols[col_name]\n",
    "    dim = tensor.shape[-1]\n",
    "    pre, sens, post =  tf.split(tensor, (col, n, (dim-(col+n))), axis=1)\n",
    "    return sens, tf.concat([pre, post], axis=1)\n"
   ]
  },
  {
   "source": [
    "### Encoder Layer"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(keras.layers.Layer):\n",
    "    def __init__(self, input_dim, latent_dim, act):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.dense_1 = Dense(128, activation=act, input_shape=(input_dim,))\n",
    "        self.latent_output =  Dense(latent_dim, name='latent_output')\n",
    "\n",
    "    def call(self, x):        \n",
    "        x = self.dense_1(x)\n",
    "        return self.latent_output(x)"
   ]
  },
  {
   "source": [
    "### Decoder Layer"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(keras.layers.Layer):\n",
    "    def __init__(self, latent_dim, act):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.dense_1 = Dense(128, activation=act, input_shape=(latent_dim,))\n",
    "        self.output_layer = Dense(input_dim)\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = self.dense_1(x)\n",
    "        return self.output_layer(x)"
   ]
  },
  {
   "source": [
    "### Autoencoder Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(keras.models.Model):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = self.encoder(x)\n",
    "        return self.decoder(x)"
   ]
  },
  {
   "source": [
    "### Dense Layer Block\n",
    "- Dense\n",
    "- LeakyReLU\n",
    "- BatchNormalization"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseBlock(keras.layers.Layer):\n",
    "    def __init__(self, n_dense,\n",
    "                       act,\n",
    "                       input_dim= False):\n",
    "\n",
    "        super(DenseBlock, self).__init__()\n",
    "        self.act = act\n",
    "        self.dense = Dense(n_dense, input_dim=input_dim) \\\n",
    "                     if input_dim else Dense(n_dense)\n",
    "        self.batchnorm = BatchNormalization()\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.dense(x)\n",
    "        x = self.act()(x)\n",
    "        return self.batchnorm(x)\n"
   ]
  },
  {
   "source": [
    "### Discriminator Layer\n",
    "- 3 `DenseBlock` layers\n",
    "- Output Layer"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(keras.layers.Layer):\n",
    "    def __init__(self, input_dim, act):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.layer_1 = DenseBlock(256, act, input_dim=input_dim)\n",
    "        self.layer_2 = DenseBlock(128, act)\n",
    "        self.output_layer = Dense(1, activation='sigmoid')\n",
    "    \n",
    "    def call(self, x):        \n",
    "        x = self.layer_1(x)\n",
    "        x = self.layer_2(x)\n",
    "        return self.output_layer(x)"
   ]
  },
  {
   "source": [
    "## Implementing the FairGAN Algorithm\n",
    "\n",
    "<img src=\"FairGAN.png\" width=\"280\">"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FairGAN(keras.Model):\n",
    "    def __init__(self,\n",
    "                 generator,\n",
    "                 D1,\n",
    "                 D2,\n",
    "                 generator_opt,\n",
    "                 D1_opt,\n",
    "                 D2_opt,\n",
    "                 **kwargs):\n",
    "        \n",
    "        super(FairGAN, self).__init__(**kwargs)\n",
    "        self.sens_var = 'Sex_Male'\n",
    "                                        \n",
    "        self.generator = generator      # Models\n",
    "        self.D1 = D1\n",
    "        self.D2 = D2\n",
    "                                        \n",
    "        self.gen_opt = generator_opt    # Optimizers\n",
    "        self.D1_opt = D1_opt\n",
    "        self.D2_opt = D2_opt\n",
    "                                        # Loss Trackers\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.gen_loss_tracker = keras.metrics.Mean(name=\"gen_loss\")\n",
    "        self.D1_loss_tracker = keras.metrics.Mean(name=\"disc_loss\")\n",
    "        self.D2_loss_tracker = keras.metrics.Mean(name=\"s_disc_loss\")\n",
    "\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "        self.total_loss_tracker,\n",
    "        self.gen_loss_tracker,\n",
    "        self.D1_loss_tracker,\n",
    "        self.D2_loss_tracker\n",
    "        ]\n",
    "\n",
    "\n",
    "    def noise(self, shape):\n",
    "        return tf.random.normal(shape=shape)\n",
    "\n",
    "\n",
    "    def call(self, inputs):\n",
    "        X = inputs\n",
    "        sens, Xy = split_tensor(X, self.sens_var)                                             \n",
    "        sens_dim = (K.shape(X)[0]//2, 1)                                         #shape = (batch_size/2, 1)\n",
    "        noise_dim = (K.shape(X)[0], latent_dim-1)                                #shape = (batch_size/2, 49)\n",
    "        s_labels = tf.concat([tf.zeros(sens_dim), tf.ones(sens_dim)], axis=0)    #shape = (batch_size, 50)\n",
    "\n",
    "        ''' Gdec input of noise P(z) and sensitive condition P(s)          '''\n",
    "        Gdec_input = tf.concat([self.noise(noise_dim), s_labels], axis=1)\n",
    "        Gdec_output =  self.generator(Gdec_input)                                #shape = (batch_size, input_dim)\n",
    "\n",
    "        ''' Conditionally generated P( x', y' | s ) for D2         '''\n",
    "        _, Xy_gen =  split_tensor(Gdec_output, self.sens_var)                                #shapes = (batch_size, 1), (batch_size, input_dim-1)\n",
    "\n",
    "        ''' D1 outputs for Real P( x, y, s) and Generated P( x', y', s')   '''\n",
    "        disc_1_output_real = self.D1(X)                                          #shape = (batch_size, 1)\n",
    "        disc_1_output_generated = self.D1(Gdec_output)                           #shape = (batch_size, 1)\n",
    "\n",
    "        ''' D2 predicting sensitive attribute on generated  P( x', y' | s ) '''\n",
    "        disc_2_output = self.D2(Xy_gen)                                          #shape = (batch_size, 1)\n",
    "\n",
    "        return Gdec_output, disc_1_output_real, disc_1_output_generated, disc_2_output, s_labels\n",
    "    \n",
    "\n",
    "\n",
    "    @tf.function\n",
    "    def adverserial_step_D1(self, data):\n",
    "        with tf.GradientTape() as gen_tape, tf.GradientTape() as D1_tape:\n",
    "            _, D1_out_real, D1_out_gen, _, _ = self.call(data)                        # Get Outputs\n",
    "            \n",
    "            D1_loss = discriminator_loss(D1_out_real, D1_out_gen, model_type='D1')    # Compute D1 loss\n",
    "            gen_loss_D1 = generator_loss(tf.ones_like(D1_out_gen),\n",
    "                                                      D1_out_gen, adversary='D1')     # Compute Generator loss\n",
    "\n",
    "        gen_grads = gen_tape.gradient(gen_loss_D1, self.generator.trainable_weights)  # Get generator gradients \n",
    "        D1_grads = D1_tape.gradient(D1_loss, self.D1.trainable_weights)               # Apply grads with optimizer\n",
    "\n",
    "        self.gen_opt.apply_gradients(zip(gen_grads, self.generator.trainable_weights)) # Get D1 gradients\n",
    "        self.D1_opt.apply_gradients(zip(D1_grads, self.D1.trainable_weights))          # Apply D1 gradients with optimizer\n",
    "        return D1_loss, gen_loss_D1\n",
    "        \n",
    "\n",
    "\n",
    "    @tf.function\n",
    "    def adverserial_step_D2(self, data):\n",
    "        with tf.GradientTape() as gen_tape, tf.GradientTape() as D2_tape:\n",
    "            _, _, _, D2_out, s_labels = self.call(data)\n",
    "\n",
    "            D2_loss = discriminator_loss(s_labels, D2_out, model_type='D2')\n",
    "            gen_loss_D2 = generator_loss(s_labels, D2_out, adversary='D2')\n",
    "\n",
    "        gen_grads = gen_tape.gradient(gen_loss_D2, self.generator.trainable_weights) \n",
    "        D2_grads = D2_tape.gradient(D2_loss, self.D2.trainable_weights)\n",
    "\n",
    "        self.gen_opt.apply_gradients(zip(gen_grads, self.generator.trainable_weights))\n",
    "        self.D2_opt.apply_gradients(zip(D2_grads, self.D2.trainable_weights))\n",
    "        return D2_loss, gen_loss_D2\n",
    "\n",
    "\n",
    "\n",
    "    @tf.function\n",
    "    def train_step(self, data):\n",
    "        Xys, _ = data\n",
    "        sens, Xy = split_tensor(Xys, self.sens_var)\n",
    "        D1_loss, gen_loss_D1 = self.adverserial_step_D1( Xys)\n",
    "        D2_loss, gen_loss_D2 = self.adverserial_step_D2( Xys)\n",
    "\n",
    "        gen_loss = gen_loss_D1 + gen_loss_D2\n",
    "        total_loss = gen_loss + D1_loss + D2_loss \n",
    "\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.gen_loss_tracker.update_state(gen_loss)\n",
    "        self.D1_loss_tracker.update_state(D1_loss)\n",
    "        self.D2_loss_tracker.update_state(D2_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"gen_loss\": self.gen_loss_tracker.result(),\n",
    "            \"D1_loss\": self.D1_loss_tracker.result(),\n",
    "            \"D2_loss\": self.D2_loss_tracker.result(),\n",
    "        }\n"
   ]
  },
  {
   "source": [
    "### Model Loss functions\n",
    "- Generator Loss (one per adversary)\n",
    "- Discriminator Loss\n",
    "- Sensitive Discriminator Loss "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.keras.losses.BinaryCrossentropy( from_logits=True)\n",
    "\n",
    "\n",
    "def generator_loss(true, pred, adversary):\n",
    "    '''\n",
    "       D1 adv loss =   cross_entropy( tf.ones_like(D1_preds), D1_preds )\n",
    "       D2 adv loss = - cross_entropy( sensitive_label, D2_preds )\n",
    "    '''\n",
    "    assert (adversary =='D1') or (adversary=='D2'), \\\n",
    "     \"adversary argument must be (str) with value 'D1' or 'D2'\"\n",
    "    if adversary == 'D1':\n",
    "        adverserial_loss = cross_entropy(true, pred)\n",
    "    elif adversary == 'D2':\n",
    "        adverserial_loss = -cross_entropy(true, pred)\n",
    "    return adverserial_loss\n",
    "\n",
    "\n",
    "\n",
    "def discriminator_loss(true, pred, model_type):\n",
    "    assert (model_type =='D1') or (model_type=='D2'), \\\n",
    "     \"model_type argument must be (str) with value 'D1' or 'D2'\"\n",
    "    if model_type == 'D1':\n",
    "        real_loss = cross_entropy(tf.ones_like(true), true)\n",
    "        fake_loss = cross_entropy(tf.zeros_like(pred), pred)\n",
    "        loss = real_loss + fake_loss\n",
    "    elif model_type == 'D2':\n",
    "        loss = cross_entropy(true, pred)\n",
    "    return loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Possible alternatives to fooling D2\n",
    "\n",
    "- Below are some alternatives to  \"- crossentropy(sens, pred_sens)\"\n",
    "'''\n",
    "@tf.function\n",
    "def invert_sensitive(pred):\n",
    "    '''\n",
    "    Idea: - Inverts the predictions of D2 on sensitive var\n",
    "    '''\n",
    "    sb = tf.cast(pred, dtype=tf.bool)\n",
    "    inv_sb = tf.math.logical_not(sb)\n",
    "    inv_sb = tf.cast(inv_sb, dtype=tf.float32)\n",
    "    return inv_sb\n",
    "\n",
    "@tf.function\n",
    "def randomize_sensitive(pred):\n",
    "    '''\n",
    "    Idea: - returns tensor with random vars between {0,1},\n",
    "            to be compared with D2 predictions on sensitive var\n",
    "    '''\n",
    "    return tf.random.uniform(shape=K.shape(pred), maxval=1) "
   ]
  },
  {
   "source": [
    "### Load Adult Dataset \n",
    "- source:  UCI ML repo"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Raw Dataset size :  48842\nSize after dropping null values:  45222\nRemoved  3620  observations\n\nCategorical  set size: (45222, 8)\nContinuous  set size: (45222, 6)\nRisk Difference M/F:\n0.17403033921542613\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       Age  fnlwgt  Education-Num  Capital Gain  Capital Loss  Hours per week  \\\n",
       "27314  1.0     0.0            1.0           0.0           0.0             1.0   \n",
       "31381  1.0     1.0            1.0           1.0           0.0             0.0   \n",
       "30713  0.0     1.0            0.0           0.0           0.0             0.0   \n",
       "40890  0.0     1.0            0.0           0.0           0.0             0.0   \n",
       "12278  0.0     0.0            0.0           0.0           0.0             0.0   \n",
       "\n",
       "       Workclass_Local-gov  Workclass_Private  Workclass_Self-emp-inc  \\\n",
       "27314                  0.0                1.0                     0.0   \n",
       "31381                  0.0                0.0                     1.0   \n",
       "30713                  0.0                1.0                     0.0   \n",
       "40890                  0.0                1.0                     0.0   \n",
       "12278                  0.0                1.0                     0.0   \n",
       "\n",
       "       Workclass_Self-emp-not-inc  ...  Relationship_Not-in-family  \\\n",
       "27314                         0.0  ...                         1.0   \n",
       "31381                         0.0  ...                         1.0   \n",
       "30713                         0.0  ...                         0.0   \n",
       "40890                         0.0  ...                         0.0   \n",
       "12278                         0.0  ...                         1.0   \n",
       "\n",
       "       Relationship_Other-relative  Relationship_Own-child  \\\n",
       "27314                          0.0                     0.0   \n",
       "31381                          0.0                     0.0   \n",
       "30713                          0.0                     1.0   \n",
       "40890                          0.0                     0.0   \n",
       "12278                          0.0                     0.0   \n",
       "\n",
       "       Relationship_Unmarried  Relationship_Wife  Race_Asian-Pac-Islander  \\\n",
       "27314                     0.0                0.0                      0.0   \n",
       "31381                     0.0                0.0                      0.0   \n",
       "30713                     0.0                0.0                      0.0   \n",
       "40890                     0.0                0.0                      0.0   \n",
       "12278                     0.0                0.0                      0.0   \n",
       "\n",
       "       Race_Black  Race_Other  Race_White  Sex_Male  \n",
       "27314         0.0         0.0         1.0       0.0  \n",
       "31381         0.0         0.0         1.0       1.0  \n",
       "30713         0.0         0.0         1.0       1.0  \n",
       "40890         0.0         0.0         1.0       1.0  \n",
       "12278         0.0         0.0         1.0       1.0  \n",
       "\n",
       "[5 rows x 101 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Age</th>\n      <th>fnlwgt</th>\n      <th>Education-Num</th>\n      <th>Capital Gain</th>\n      <th>Capital Loss</th>\n      <th>Hours per week</th>\n      <th>Workclass_Local-gov</th>\n      <th>Workclass_Private</th>\n      <th>Workclass_Self-emp-inc</th>\n      <th>Workclass_Self-emp-not-inc</th>\n      <th>...</th>\n      <th>Relationship_Not-in-family</th>\n      <th>Relationship_Other-relative</th>\n      <th>Relationship_Own-child</th>\n      <th>Relationship_Unmarried</th>\n      <th>Relationship_Wife</th>\n      <th>Race_Asian-Pac-Islander</th>\n      <th>Race_Black</th>\n      <th>Race_Other</th>\n      <th>Race_White</th>\n      <th>Sex_Male</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>27314</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>31381</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>30713</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>40890</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>12278</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 101 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "data = load_adult(binarize=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = [i.astype(np.float32) for i in data]\n",
    "Xy_train = np.hstack([X_train, y_train.reshape(-1,1)])\n",
    "Xy_test = np.hstack([X_test, y_test.reshape(-1,1)])\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.17583320170589165"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "cn = list(X_train.columns)+['Target']\n",
    "Xys_cols = dict([(j,i) for i,j in enumerate(cn)])\n",
    "\n",
    "\n",
    "def risk_difference(df, sens_attr):\n",
    "    s_col = Xys_cols[sens_attr]\n",
    "    n = df.shape[0]\n",
    "    y = df[:,-1]\n",
    "    s = df[:,s_col] \n",
    "    P_y1_s0 = df[(y == 1) & (s == 0)].shape[0] / n\n",
    "    P_y1_s1 = df[(y == 1) & (s == 1)].shape[0] / n\n",
    "    return P_y1_s1 - P_y1_s0\n",
    "risk_difference(Xy_train, 'Sex_Male')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TensorShape([31655, 50])"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "input_dim = Xy_train.shape[-1]\n",
    "batch_size = Xy_train.shape[0]\n",
    "\n",
    "latent_dim = 50\n",
    "noise_dim = latent_dim\n",
    "\n",
    "noise = tf.random.normal(shape=(batch_size, noise_dim))\n",
    "noise.shape"
   ]
  },
  {
   "source": [
    "### Define all models"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(input_dim, latent_dim, 'relu')\n",
    "decoder = Decoder(latent_dim, 'relu')\n",
    "\n",
    "autoencoder = AutoEncoder(encoder, decoder)\n",
    "\n",
    "generator = autoencoder.decoder\n",
    "\n",
    "D1 = Discriminator(input_dim, LeakyReLU)\n",
    "D2 = Discriminator(input_dim-1, LeakyReLU)\n"
   ]
  },
  {
   "source": [
    "### Check Model Outputs\n",
    "#### AutoEncoder Output"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TensorShape([31655, 102])"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "ae_output = autoencoder(Xy_train)\n",
    "ae_output.shape"
   ]
  },
  {
   "source": [
    "#### Generator Output"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TensorShape([31655, 102])"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "g_outputs = generator(noise)\n",
    "g_outputs.shape"
   ]
  },
  {
   "source": [
    "#### Discriminator output"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TensorShape([31655, 1])"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "d_outputs = D1(g_outputs)\n",
    "d_outputs.shape"
   ]
  },
  {
   "source": [
    "#### Sensitive Discriminator output"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TensorShape([31655, 1])"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "sens, gen_xy = split_tensor(g_outputs, 'Sex_Male', 1)\n",
    "s_d_outputs = D2(gen_xy)\n",
    "s_d_outputs.shape"
   ]
  },
  {
   "source": [
    "### Check Model Losses\n",
    "#### Discriminator loss"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=1.4107502>"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "discriminator_loss(X_train.values, g_outputs, model_type='D1')"
   ]
  },
  {
   "source": [
    "#### Generator loss"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.61064565>"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "generator_loss(sens, d_outputs, adversary='D1')"
   ]
  },
  {
   "source": [
    "#### Sensitive Discriminator loss"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.6978872>"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "sensitive = X_train.values[:,0].reshape(-1,1)\n",
    "discriminator_loss(sensitive, s_d_outputs, model_type='D2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=-0.81881565>"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "generator_loss(tf.ones_like(s_d_outputs),s_d_outputs, adversary='D2')"
   ]
  },
  {
   "source": [
    "## Pre-train Auto-Encoder and evaluate"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "autoencoder.compile(loss='mse', optimizer='rmsprop')\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                   patience=2,\n",
    "                                                    restore_best_weights=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/200\n",
      "248/248 [==============================] - 2s 7ms/step - loss: 0.0322 - val_loss: 0.0088\n",
      "Epoch 2/200\n",
      "248/248 [==============================] - 1s 5ms/step - loss: 0.0073 - val_loss: 0.0048\n",
      "Epoch 3/200\n",
      "248/248 [==============================] - 1s 5ms/step - loss: 0.0046 - val_loss: 0.0040\n",
      "Epoch 4/200\n",
      "248/248 [==============================] - 1s 5ms/step - loss: 0.0035 - val_loss: 0.0028\n",
      "Epoch 5/200\n",
      "248/248 [==============================] - 1s 5ms/step - loss: 0.0031 - val_loss: 0.0026\n",
      "Epoch 6/200\n",
      "248/248 [==============================] - 1s 5ms/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 7/200\n",
      "248/248 [==============================] - 1s 5ms/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 8/200\n",
      "248/248 [==============================] - 1s 5ms/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 9/200\n",
      "248/248 [==============================] - 1s 5ms/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 10/200\n",
      "248/248 [==============================] - 1s 5ms/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 11/200\n",
      "248/248 [==============================] - 1s 5ms/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 12/200\n",
      "248/248 [==============================] - 1s 5ms/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 13/200\n",
      "248/248 [==============================] - 1s 5ms/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 14/200\n",
      "248/248 [==============================] - 1s 5ms/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 15/200\n",
      "248/248 [==============================] - 1s 5ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 16/200\n",
      "248/248 [==============================] - 1s 5ms/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 17/200\n",
      "248/248 [==============================] - 1s 4ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 18/200\n",
      "248/248 [==============================] - 1s 4ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 19/200\n",
      "248/248 [==============================] - 1s 4ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 20/200\n",
      "248/248 [==============================] - 1s 5ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 21/200\n",
      "248/248 [==============================] - 1s 5ms/step - loss: 0.0012 - val_loss: 0.0012\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1dd3a625880>"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "autoencoder.fit(Xy_train, Xy_train,\n",
    "                                validation_data=(Xy_test, Xy_test),\n",
    "                                 batch_size=128,\n",
    "                                  epochs=200,\n",
    "                                   callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "MSE : 0.00043\n"
     ]
    }
   ],
   "source": [
    "def evaluate_ae(test_set):    \n",
    "    preds = autoencoder.predict(test_set)\n",
    "    preds_b = np.where(preds>0.5,1,0).astype(float)\n",
    "    return round(tf.keras.losses.mean_squared_error(test_set, preds_b).numpy().mean(), 5)\n",
    "\n",
    "\n",
    "print(\"MSE :\",evaluate_ae(Xy_test) )"
   ]
  },
  {
   "source": [
    "### Define optimizers"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_opt = tf.keras.optimizers.Adam(1e-3)\n",
    "disc_opt = tf.keras.optimizers.Adam(1e-3)\n",
    "s_disc_opt = tf.keras.optimizers.Adam(1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "FGan = FairGAN(autoencoder.decoder,\n",
    "             D1, D2,\n",
    "            gen_opt, disc_opt, s_disc_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/50\n",
      "124/124 [==============================] - 4s 11ms/step - loss: 3.0267 - gen_loss: 3.5835 - D1_loss: 1.0214 - D2_loss: 0.6757\n",
      "Epoch 2/50\n",
      "124/124 [==============================] - 1s 11ms/step - loss: 7.9107 - gen_loss: 4.1753 - D1_loss: 0.3297 - D2_loss: 0.6442\n",
      "Epoch 3/50\n",
      "124/124 [==============================] - 2s 12ms/step - loss: 2.2692 - gen_loss: 0.2615 - D1_loss: 1.5347 - D2_loss: 0.6446\n",
      "Epoch 4/50\n",
      "124/124 [==============================] - 2s 12ms/step - loss: 2.7519 - gen_loss: 0.9326 - D1_loss: 1.1452 - D2_loss: 0.6858\n",
      "Epoch 5/50\n",
      "124/124 [==============================] - 2s 12ms/step - loss: 2.9702 - gen_loss: 0.5620 - D1_loss: 1.5213 - D2_loss: 0.6670\n",
      "Epoch 6/50\n",
      "124/124 [==============================] - 2s 12ms/step - loss: 2.3641 - gen_loss: 0.1349 - D1_loss: 1.5412 - D2_loss: 0.6833\n",
      "Epoch 7/50\n",
      "124/124 [==============================] - 2s 12ms/step - loss: 2.3601 - gen_loss: 0.5447 - D1_loss: 1.2946 - D2_loss: 0.6836\n",
      "Epoch 8/50\n",
      "124/124 [==============================] - 2s 12ms/step - loss: 2.6052 - gen_loss: 0.3480 - D1_loss: 1.2592 - D2_loss: 0.6845\n",
      "Epoch 9/50\n",
      "124/124 [==============================] - 2s 12ms/step - loss: 2.2090 - gen_loss: 0.0472 - D1_loss: 1.4859 - D2_loss: 0.6881\n",
      "Epoch 10/50\n",
      "124/124 [==============================] - 2s 13ms/step - loss: 2.3383 - gen_loss: 0.2351 - D1_loss: 1.4280 - D2_loss: 0.6906\n",
      "Epoch 11/50\n",
      "124/124 [==============================] - 2s 13ms/step - loss: 2.1832 - gen_loss: 0.1864 - D1_loss: 1.1319 - D2_loss: 0.6931\n",
      "Epoch 12/50\n",
      "124/124 [==============================] - 2s 14ms/step - loss: 2.1880 - gen_loss: 0.2423 - D1_loss: 1.1716 - D2_loss: 0.6833\n",
      "Epoch 13/50\n",
      "124/124 [==============================] - 2s 15ms/step - loss: 2.4498 - gen_loss: 0.4607 - D1_loss: 1.3194 - D2_loss: 0.6940\n",
      "Epoch 14/50\n",
      "124/124 [==============================] - 2s 14ms/step - loss: 2.1470 - gen_loss: 0.1855 - D1_loss: 1.2983 - D2_loss: 0.6837\n",
      "Epoch 15/50\n",
      "124/124 [==============================] - 2s 13ms/step - loss: 2.3519 - gen_loss: 0.3922 - D1_loss: 1.3012 - D2_loss: 0.6868\n",
      "Epoch 16/50\n",
      "124/124 [==============================] - 2s 15ms/step - loss: 2.4764 - gen_loss: 0.3982 - D1_loss: 1.4668 - D2_loss: 0.6892\n",
      "Epoch 17/50\n",
      "124/124 [==============================] - 2s 14ms/step - loss: 2.1438 - gen_loss: 0.2461 - D1_loss: 1.2828 - D2_loss: 0.6829\n",
      "Epoch 18/50\n",
      "124/124 [==============================] - 2s 14ms/step - loss: 2.2314 - gen_loss: 0.1922 - D1_loss: 1.3815 - D2_loss: 0.6956\n",
      "Epoch 19/50\n",
      "124/124 [==============================] - 2s 14ms/step - loss: 2.5396 - gen_loss: 0.3525 - D1_loss: 1.4761 - D2_loss: 0.6890\n",
      "Epoch 20/50\n",
      "124/124 [==============================] - 2s 13ms/step - loss: 2.3048 - gen_loss: 0.3589 - D1_loss: 1.2645 - D2_loss: 0.6938\n",
      "Epoch 21/50\n",
      "124/124 [==============================] - 2s 13ms/step - loss: 2.2832 - gen_loss: 0.3210 - D1_loss: 1.1866 - D2_loss: 0.6892\n",
      "Epoch 22/50\n",
      "124/124 [==============================] - 2s 13ms/step - loss: 2.4522 - gen_loss: 0.3661 - D1_loss: 1.3229 - D2_loss: 0.6870\n",
      "Epoch 23/50\n",
      "124/124 [==============================] - 2s 13ms/step - loss: 2.2848 - gen_loss: 0.1383 - D1_loss: 1.4156 - D2_loss: 0.6942\n",
      "Epoch 24/50\n",
      "124/124 [==============================] - 2s 13ms/step - loss: 2.2599 - gen_loss: 0.2468 - D1_loss: 1.2302 - D2_loss: 0.6899\n",
      "Epoch 25/50\n",
      "124/124 [==============================] - 2s 13ms/step - loss: 2.2643 - gen_loss: 0.2745 - D1_loss: 1.1978 - D2_loss: 0.6855\n",
      "Epoch 26/50\n",
      "124/124 [==============================] - 2s 13ms/step - loss: 2.1101 - gen_loss: 0.1920 - D1_loss: 1.3198 - D2_loss: 0.6901\n",
      "Epoch 27/50\n",
      "124/124 [==============================] - 2s 13ms/step - loss: 2.2322 - gen_loss: 0.1501 - D1_loss: 1.3063 - D2_loss: 0.6898\n",
      "Epoch 28/50\n",
      "124/124 [==============================] - 2s 13ms/step - loss: 2.2823 - gen_loss: 0.2725 - D1_loss: 1.2549 - D2_loss: 0.6864\n",
      "Epoch 29/50\n",
      "124/124 [==============================] - 2s 13ms/step - loss: 2.1888 - gen_loss: 0.2642 - D1_loss: 1.2679 - D2_loss: 0.6900\n",
      "Epoch 30/50\n",
      "124/124 [==============================] - 2s 13ms/step - loss: 2.3000 - gen_loss: 0.3385 - D1_loss: 1.3655 - D2_loss: 0.6877\n",
      "Epoch 31/50\n",
      "124/124 [==============================] - 2s 13ms/step - loss: 2.3371 - gen_loss: 0.3614 - D1_loss: 1.2483 - D2_loss: 0.6888\n",
      "Epoch 32/50\n",
      "124/124 [==============================] - 2s 13ms/step - loss: 2.1619 - gen_loss: 0.3565 - D1_loss: 1.1345 - D2_loss: 0.6848\n",
      "Epoch 33/50\n",
      "124/124 [==============================] - 2s 13ms/step - loss: 2.4161 - gen_loss: 0.5465 - D1_loss: 1.2851 - D2_loss: 0.6833\n",
      "Epoch 34/50\n",
      "124/124 [==============================] - 2s 13ms/step - loss: 2.3506 - gen_loss: 0.4689 - D1_loss: 1.1372 - D2_loss: 0.6899\n",
      "Epoch 35/50\n",
      "124/124 [==============================] - 2s 13ms/step - loss: 2.3584 - gen_loss: 0.3977 - D1_loss: 1.1482 - D2_loss: 0.6816\n",
      "Epoch 36/50\n",
      "124/124 [==============================] - 2s 13ms/step - loss: 2.4676 - gen_loss: 0.6254 - D1_loss: 1.0921 - D2_loss: 0.6851\n",
      "Epoch 37/50\n",
      "124/124 [==============================] - 2s 13ms/step - loss: 2.4144 - gen_loss: 0.3984 - D1_loss: 1.3543 - D2_loss: 0.6910\n",
      "Epoch 38/50\n",
      "124/124 [==============================] - 2s 13ms/step - loss: 2.3761 - gen_loss: 0.4814 - D1_loss: 1.0406 - D2_loss: 0.6829\n",
      "Epoch 39/50\n",
      "124/124 [==============================] - 2s 13ms/step - loss: 2.4082 - gen_loss: 0.4721 - D1_loss: 1.2334 - D2_loss: 0.6877\n",
      "Epoch 40/50\n",
      "124/124 [==============================] - 2s 13ms/step - loss: 2.1990 - gen_loss: 0.3400 - D1_loss: 1.1693 - D2_loss: 0.6923\n",
      "Epoch 41/50\n",
      "124/124 [==============================] - 2s 13ms/step - loss: 2.3632 - gen_loss: 0.3612 - D1_loss: 1.2039 - D2_loss: 0.6936\n",
      "Epoch 42/50\n",
      "124/124 [==============================] - 2s 13ms/step - loss: 2.4989 - gen_loss: 0.4322 - D1_loss: 1.4149 - D2_loss: 0.6858\n",
      "Epoch 43/50\n",
      "124/124 [==============================] - 2s 13ms/step - loss: 2.3561 - gen_loss: 0.4766 - D1_loss: 1.1259 - D2_loss: 0.6904\n",
      "Epoch 44/50\n",
      "124/124 [==============================] - 2s 13ms/step - loss: 2.2968 - gen_loss: 0.4600 - D1_loss: 1.1721 - D2_loss: 0.6853\n",
      "Epoch 45/50\n",
      "124/124 [==============================] - 2s 13ms/step - loss: 2.3465 - gen_loss: 0.3923 - D1_loss: 1.3114 - D2_loss: 0.6872\n",
      "Epoch 46/50\n",
      "124/124 [==============================] - 2s 13ms/step - loss: 2.2775 - gen_loss: 0.4769 - D1_loss: 1.1171 - D2_loss: 0.6921\n",
      "Epoch 47/50\n",
      "124/124 [==============================] - 2s 13ms/step - loss: 2.4359 - gen_loss: 0.4492 - D1_loss: 1.2686 - D2_loss: 0.6813\n",
      "Epoch 48/50\n",
      "124/124 [==============================] - 2s 13ms/step - loss: 2.2662 - gen_loss: 0.3942 - D1_loss: 1.1919 - D2_loss: 0.6811\n",
      "Epoch 49/50\n",
      "124/124 [==============================] - 2s 13ms/step - loss: 2.2615 - gen_loss: 0.5725 - D1_loss: 1.0619 - D2_loss: 0.6836\n",
      "Epoch 50/50\n",
      "124/124 [==============================] - 2s 13ms/step - loss: 2.2755 - gen_loss: 0.5024 - D1_loss: 1.0278 - D2_loss: 0.6960\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1dd6470b1c0>"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "FGan.compile()\n",
    "FGan.fit(Xy_train[:-1,:], Xy_train[:-1,:], batch_size=256, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "true = Xy_test[:-1,:]\n",
    "Xy_gen,_,_,_,_ = FGan(true)"
   ]
  },
  {
   "source": [
    "## Fairness of generated data\n",
    "- Metric:  Risk difference"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def risk_difference(df, sens_attr):\n",
    "    s_col = Xys_cols[sens_attr]\n",
    "    n = df.shape[0]\n",
    "    P_y1_s0 = df[(df[:,-1] == 1) & (df[:,s_col] == 0)].shape[0] / n\n",
    "    P_y1_s1 = df[(df[:,-1] == 1) & (df[:,s_col] == 1)].shape[0] / n\n",
    "    return P_y1_s1 - P_y1_s0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.17583320170589165"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "# Risk Diff in original dataset\n",
    "risk_difference(Xy_train, 'Sex_Male')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "-0.002948547840188706"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "# Risk difference in generated data\n",
    "\n",
    "Xy_gen = Xy_gen.numpy()\n",
    "Xy_gen[:,-2] = np.where(Xy_gen[:,-2]>0.5,1,0)\n",
    "Xy_gen[:,-1] = np.where(Xy_gen[:,-1]>0.5,1,0)\n",
    "risk_difference(Xy_gen, 'Sex_Male')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(11079.0, 9139.0)"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "Xy_gen[:,-2].sum(), true[:,-2].sum()"
   ]
  },
  {
   "source": [
    "## Utility of generated data: \n",
    "Comparing classifier performance in predicting income from real and generated data\n",
    "- Real2Real classification\n",
    "- Synth2Real classification"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.10783"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "# MSE compared to original\n",
    "round(tf.keras.losses.mse(true, Xy_gen).numpy().mean(),5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.7521928208152133"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "1 - (Xy_test[:,-1].sum()/len(Xy_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "RD: 0.15\n",
      "ACC: 0.84\n",
      "\n",
      "      0     1\n",
      "0  9460   745\n",
      "1  1455  1907\n",
      "--------------- \n",
      "\n",
      "RD: 0.03\n",
      "ACC: 0.76\n",
      "\n",
      "       0    1\n",
      "0  10055  150\n",
      "1   3060  302\n",
      "--------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "split_target = lambda x : (x[:, :-1], x[:, -1])\n",
    "\n",
    "X_test, y_test = split_target(Xy_test)\n",
    "\n",
    "for dset in [Xy_train, Xy_gen]:\n",
    "    X_train, y_train = split_target(dset)\n",
    "    clf = LinearSVC(random_state=0, tol=1e-5).fit(X_train, y_train)\n",
    "    pred = clf.predict(X_test)\n",
    "    print('RD:', round(risk_difference(np.hstack([X_test, pred.reshape(-1,1)]), 'Sex_Male'),2))\n",
    "    print('ACC:',round(clf.score(X_test, y_test), 2))\n",
    "    print()\n",
    "    print(pd.DataFrame(confusion_matrix(y_test, pred)))\n",
    "    print('-'*15, '\\n')\n"
   ]
  }
 ]
}